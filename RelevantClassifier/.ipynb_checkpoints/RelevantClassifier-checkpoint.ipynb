{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text     relevant\n",
      "0  destin charger charg normal car 7kw super netw...     relevant\n",
      "1  thank make frick spaceflight feel normal const...  notRelevant\n",
      "2             super charger work hard holiday season     relevant\n",
      "3       egyptian bitch blush vintag tux dilling tuck  notRelevant\n",
      "4                       angel heaven silk bed fill _  notRelevant\n"
     ]
    }
   ],
   "source": [
    "# create a dataframe to store the information\n",
    "df = pd.DataFrame(columns=['text', 'relevant'])\n",
    "\n",
    "handle = open('../classify.json')\n",
    "\n",
    "for line in handle:\n",
    "    item = json.loads(line)\n",
    "    if item['isRelevant'] == 0:\n",
    "        temp = pd.DataFrame([[item['text'], 'notRelevant']], columns=['text', 'relevant'])\n",
    "    else:\n",
    "        temp = pd.DataFrame([[item['text'], 'relevant']], columns=['text', 'relevant'])\n",
    "    df = df.append(temp, ignore_index=True)\n",
    "    \n",
    "handle.close()\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  relevant\n",
      "0  destin charger charg normal car 7kw super netw...         1\n",
      "1  thank make frick spaceflight feel normal const...         0\n",
      "2             super charger work hard holiday season         1\n",
      "3       egyptian bitch blush vintag tux dilling tuck         0\n",
      "4                       angel heaven silk bed fill _         0\n"
     ]
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df['relevant'])\n",
    "labels = le.transform(df['relevant']) \n",
    "df['relevant'] = labels\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "def calcScores(y, pred):\n",
    "    averageType = \"binary\"\n",
    "    accuracy = accuracy_score(y, pred)\n",
    "    print(\"Accuracy: %0.4f\" % (accuracy))\n",
    "    recall = recall_score(y, pred, average=averageType)\n",
    "    print(\"Recall: %0.4f\" % recall)\n",
    "    precision = precision_score(y, pred, average=averageType)\n",
    "    print(\"Precision: %0.4f\" % precision)\n",
    "    f1 = f1_score(y, pred, average=averageType)\n",
    "    print(\"F-Score: %0.4f\" % f1)\n",
    "    return accuracy, recall, precision, f1\n",
    "\n",
    "##split data\n",
    "x_train, x_test, y_train, y_test = train_test_split(df['text'], df['relevant'], test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Naive Bayes-----\n",
      "Train\n",
      "Accuracy: 0.9291\n",
      "Recall: 0.9477\n",
      "Precision: 0.8942\n",
      "F-Score: 0.9202\n",
      "\n",
      "Test\n",
      "Accuracy: 0.8736\n",
      "Recall: 0.9094\n",
      "Precision: 0.8111\n",
      "F-Score: 0.8575\n",
      "\n",
      "-----SVM-----\n",
      "Train\n",
      "Accuracy: 0.7973\n",
      "Recall: 0.5771\n",
      "Precision: 0.9247\n",
      "F-Score: 0.7107\n",
      "\n",
      "Test\n",
      "Accuracy: 0.7376\n",
      "Recall: 0.4375\n",
      "Precision: 0.8706\n",
      "F-Score: 0.5823\n"
     ]
    }
   ],
   "source": [
    "##Naive Bayes\n",
    "text_clf_pipe_nb = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('mnb', MultinomialNB(fit_prior=False)),])\n",
    "\n",
    "text_clf_nb = text_clf_pipe_nb.fit(x_train, y_train)\n",
    "train_pred_nb = text_clf_nb.predict(x_train)\n",
    "test_pred_nb = text_clf_nb.predict(x_test)\n",
    "\n",
    "print(\"-----Naive Bayes-----\")\n",
    "print(\"Train\")\n",
    "values_train_nb = calcScores(y_train, train_pred_nb)\n",
    "print(\"\\nTest\")\n",
    "values_test_nb = calcScores(y_test, test_pred_nb)\n",
    "\n",
    "##SVM\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf_pipe_svm = Pipeline([('vect', CountVectorizer()),\n",
    "                              ('tfidf', TfidfTransformer()),\n",
    "                              ('clf-svm', SGDClassifier(loss='hinge', \n",
    "                                                        penalty='l2', alpha=1e-3, \n",
    "                                                        max_iter=5, tol=None, \n",
    "                                                        random_state=42))])\n",
    "text_clf_svm = text_clf_pipe_svm.fit(x_train, y_train)\n",
    "train_pred_svm = text_clf_svm.predict(x_train)\n",
    "test_pred_svm = text_clf_svm.predict(x_test)\n",
    "\n",
    "print(\"\\n-----SVM-----\")\n",
    "print(\"Train\")\n",
    "values_train_svm = calcScores(y_train, train_pred_svm)\n",
    "print(\"\\nTest\")\n",
    "values_test_svm = calcScores(y_test, test_pred_svm)\n",
    "scores = np.column_stack((values_train_nb, values_train_svm, values_test_nb, values_test_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x400 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##plot confusion matrices\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "def normalizeCM(cm):\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    return cm\n",
    "\n",
    "def createCmDf(cm):\n",
    "    df_cm = pd.DataFrame(cm, index = [\"Relevant\", \"Not Relevant\"], columns = [\"Relevant\", \"Not Relevant\"])\n",
    "    return df_cm\n",
    "cm_nb = confusion_matrix(y_test,test_pred_nb, labels = [1, 0])\n",
    "#cm_nb = normalizeCM(cm_nb)\n",
    "\n",
    "cm_svm = confusion_matrix(y_test,test_pred_svm, labels = [1, 0])\n",
    "#cm_svm = normalizeCM(cm_svm)\n",
    "\n",
    "df_nb = createCmDf(cm_nb)\n",
    "df_svm = createCmDf(cm_svm)\n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(ncols=2, figsize=(10, 4))\n",
    "fmt = '10d'\n",
    "im = sn.heatmap(df_nb, ax=ax1, annot=True, cmap='coolwarm', fmt=fmt)\n",
    "ax1.set_title(\"Naive Bayes\")\n",
    "ax1.set_xlabel(\"True\")\n",
    "ax1.set_ylabel(\"Predicted\")\n",
    "sn.heatmap(df_svm, ax=ax2, annot=True, cmap='coolwarm', fmt=fmt)\n",
    "ax2.set_title(\"SVM\")\n",
    "ax2.set_xlabel(\"True\")\n",
    "ax2.set_ylabel(\"Predicted\")\n",
    "mappable = im.get_children()[0]\n",
    "#plt.colorbar(mappable, ax = [ax1,ax2],orientation = 'horizontal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
