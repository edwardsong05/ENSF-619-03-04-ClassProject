{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate word clouds to see frequent words/topics to determine stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0430ed923ef4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRegexpTokenizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import json\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from wordcloud import WordCloud\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# words used in the filter\n",
    "filterWords = {\"tesla\", \"elon\", \"musk\", \"elonmusk\", \"tsla\", \"roadster\", \"supercharger\", \"powerwall\", \"powerpack\", \"modely\",\n",
    "               \"model3\", \"modelx\", \"teslamodely\", \"teslamodels\", \"teslamodel3\", \"teslamodelx\", \"spacex\",\n",
    "               \"teslasuv\", \"teslascience\"}\n",
    "\n",
    "# bigrams used in the filter\n",
    "filterBigrams = {(\"model\", \"y\"), (\"model\", \"s\"), (\"model\", \"3\"), (\"model\", \"x\"), (\"electric\", \"vehicle\"),\n",
    "                 (\"electric\", \"car\"), (\"electric\", \"suv\"), (\"electric\", \"supercar\")}\n",
    "\n",
    "# stop words found using the word cloud (manual extraction)\n",
    "cloud = {'year', 'amp', 'us', 'at_tesla'}\n",
    "\n",
    "# add filter words to the stop words\n",
    "for word in filterWords:\n",
    "    stop_words.add(word)\n",
    "    \n",
    "# add filter bigrams to the stop words\n",
    "for bi1, bi2 in filterBigrams:\n",
    "    stop_words.add(bi1)\n",
    "    stop_words.add(bi2)\n",
    "    \n",
    "# add cloud to the stop words\n",
    "for word in cloud:\n",
    "    stop_words.add(word)\n",
    "\n",
    "counts = defaultdict(int)\n",
    "\n",
    "handle = open('../classify.json', encoding='utf8')\n",
    "\n",
    "for line in handle:\n",
    "    item = json.loads(line)\n",
    "    if item['isRelevant'] == 1:  # get relevant tweets\n",
    "        tokens = tokenizer.tokenize(item['text'].lower())\n",
    "        for token in tokens:\n",
    "            if token not in stop_words:\n",
    "                counts[token] += 1\n",
    "        \n",
    "handle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = WordCloud(background_color=\"white\", max_words=100, width=1000, height=500)\n",
    "wc.generate_from_frequencies(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the most common words\n",
    "counts2 = []\n",
    "for i, j in counts.items():\n",
    "    counts2.append((i,j))\n",
    "counts2.sort(key=lambda x:x[1], reverse=True)\n",
    "for i in counts2:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# look at common words in irrelevant tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irr = defaultdict(int)\n",
    "\n",
    "handle = open('../classify.json', encoding='utf8')\n",
    "\n",
    "for line in handle:\n",
    "    item = json.loads(line)\n",
    "    if item['isRelevant'] == 0:  # irrelevant tweets\n",
    "        tokens = tokenizer.tokenize(item['text'].lower())\n",
    "        for token in tokens:\n",
    "            if token not in stop_words:\n",
    "                irr[token] += 1\n",
    "        \n",
    "handle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = WordCloud(background_color=\"white\", max_words=100, width=1000, height=500)\n",
    "wc.generate_from_frequencies(irr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# look at common words in negative tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg = defaultdict(int)\n",
    "\n",
    "handle = open('../classify.json', encoding='utf8')\n",
    "\n",
    "for line in handle:\n",
    "    item = json.loads(line)\n",
    "    if item['isRelevant'] == 1 and item['sentiment'] == 0:  # get relevant tweets\n",
    "        var += 1\n",
    "        tokens = tokenizer.tokenize(item['text'].lower())\n",
    "        for token in tokens:\n",
    "            if token not in stop_words:\n",
    "                neg[token] += 1\n",
    "handle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = WordCloud(background_color=\"white\", max_words=100, width=1000, height=500)\n",
    "wc.generate_from_frequencies(neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# look at positive words in tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = defaultdict(int)\n",
    "\n",
    "handle = open('../classify.json', encoding='utf8')\n",
    "\n",
    "for line in handle:\n",
    "    item = json.loads(line)\n",
    "    if item['isRelevant'] == 1 and item['sentiment'] == 2:  # get relevant tweets\n",
    "        var += 1\n",
    "        tokens = tokenizer.tokenize(item['text'].lower())\n",
    "        for token in tokens:\n",
    "            if token not in stop_words:\n",
    "                pos[token] += 1\n",
    "handle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = WordCloud(background_color=\"white\", max_words=100, width=1000, height=500)\n",
    "wc.generate_from_frequencies(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
